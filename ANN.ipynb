{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puoK4M-Ijs1w",
        "outputId": "866735e4-755d-4c4c-eeb5-c79467224131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2674 - accuracy: 0.8982 - val_loss: 0.1366 - val_accuracy: 0.9589\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9779 - val_loss: 0.1300 - val_accuracy: 0.9396\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9882 - val_loss: 0.0943 - val_accuracy: 0.9771\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.0974 - val_accuracy: 0.9674\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9949 - val_loss: 0.0868 - val_accuracy: 0.9698\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9952 - val_loss: 0.0868 - val_accuracy: 0.9686\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9973 - val_loss: 0.1006 - val_accuracy: 0.9638\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 0.1013 - val_accuracy: 0.9650\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.1030 - val_accuracy: 0.9626\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 0.1012 - val_accuracy: 0.9638\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.96\n",
            "Confusion Matrix:\n",
            " [[708  31]\n",
            " [  8 288]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       739\n",
            "           1       0.90      0.97      0.94       296\n",
            "\n",
            "    accuracy                           0.96      1035\n",
            "   macro avg       0.95      0.97      0.95      1035\n",
            "weighted avg       0.96      0.96      0.96      1035\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "# Load your cleaned dataset (replace 'cleaned_dataset.csv' with the actual file name)\n",
        "df_cleaned = pd.read_csv('cleaned_dataset.csv')\n",
        "\n",
        "# Assuming 'target' is the column you want to predict\n",
        "target_column = 'Prediction'\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df_cleaned.drop(columns=[target_column])\n",
        "y = df_cleaned[target_column]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer and first hidden layer\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = [1 if prob >= 0.5 else 0 for prob in y_pred_prob]\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ]
    }
  ]
}