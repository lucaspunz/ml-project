{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puoK4M-Ijs1w",
        "outputId": "d4f7813f-5869-4d07-d4ba-804c8e2a118e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3568 - accuracy: 0.8510 - val_loss: 0.1864 - val_accuracy: 0.9348\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9686 - val_loss: 0.1442 - val_accuracy: 0.9589\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9831 - val_loss: 0.1234 - val_accuracy: 0.9650\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.1140 - val_accuracy: 0.9686\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9930 - val_loss: 0.1116 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.0283 - accuracy: 0.9943 - val_loss: 0.1070 - val_accuracy: 0.9638\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.1281 - val_accuracy: 0.9457\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.1078 - val_accuracy: 0.9686\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.0164 - accuracy: 0.9976 - val_loss: 0.1104 - val_accuracy: 0.9638\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.1270 - val_accuracy: 0.9577\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.95\n",
            "Confusion Matrix:\n",
            " [[699  40]\n",
            " [  8 288]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97       739\n",
            "           1       0.88      0.97      0.92       296\n",
            "\n",
            "    accuracy                           0.95      1035\n",
            "   macro avg       0.93      0.96      0.94      1035\n",
            "weighted avg       0.96      0.95      0.95      1035\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "# Load your cleaned dataset (replace 'cleaned_dataset.csv' with the actual file name)\n",
        "df_cleaned = pd.read_csv('cleaned_dataset.csv')\n",
        "\n",
        "# Assuming 'target' is the column you want to predict\n",
        "target_column = 'Prediction'\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df_cleaned.drop(columns=[target_column])\n",
        "y = df_cleaned[target_column]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer and first hidden layer\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = [1 if prob >= 0.5 else 0 for prob in y_pred_prob]\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH99oFWA3NpG",
        "outputId": "917e122c-e9b6-414b-b1a6-9bd55b41fcc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.14.0 requires keras<2.15,>=2.14.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Load your cleaned dataset (replace 'cleaned_dataset.csv' with the actual file name)\n",
        "df_cleaned = pd.read_csv('cleaned_dataset.csv')\n",
        "\n",
        "# Assuming 'target' is the column you want to predict\n",
        "target_column = 'Prediction'\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df_cleaned.drop(columns=[target_column])\n",
        "y = df_cleaned[target_column]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the base model for KerasClassifier\n",
        "def create_model(learning_rate=0.001, units=64):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=units, activation='relu', input_dim=X_train.shape[1]))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Wrap the Keras model in a scikit-learn classifier\n",
        "keras_model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'units': [32, 64, 128],\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform the grid search\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_result.best_params_)\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred_prob = grid_result.best_estimator_.predict(X_test)\n",
        "y_pred = [1 if prob >= 0.5 else 0 for prob in y_pred_prob]\n",
        "\n",
        "# Evaluate the performance of the best model\n",
        "result_accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {result_accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzebkcNbjqSV",
        "outputId": "9da2e740-3037-4e4e-c040-2e9fd3933c46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-80de1badea61>:41: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 3ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 3ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 3ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "44/44 [==============================] - 0s 2ms/step\n",
            "Best Hyperparameters: {'learning_rate': 0.001, 'units': 32}\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.97\n",
            "Confusion Matrix:\n",
            " [[717  22]\n",
            " [  6 290]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       739\n",
            "           1       0.93      0.98      0.95       296\n",
            "\n",
            "    accuracy                           0.97      1035\n",
            "   macro avg       0.96      0.97      0.97      1035\n",
            "weighted avg       0.97      0.97      0.97      1035\n",
            "\n"
          ]
        }
      ]
    }
  ]
}