{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puoK4M-Ijs1w",
        "outputId": "962cee7d-b1c7-41b3-aaee-d147651116b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 2s 6ms/step - loss: 0.2326 - accuracy: 0.9078 - val_loss: 0.1305 - val_accuracy: 0.9601\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9794 - val_loss: 0.1041 - val_accuracy: 0.9734\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9870 - val_loss: 0.0905 - val_accuracy: 0.9662\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9934 - val_loss: 0.0887 - val_accuracy: 0.9674\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.0916 - val_accuracy: 0.9674\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.0853 - val_accuracy: 0.9698\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 0.0948 - val_accuracy: 0.9698\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9982 - val_loss: 0.0909 - val_accuracy: 0.9650\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.1047 - val_accuracy: 0.9589\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.1007 - val_accuracy: 0.9650\n",
            "33/33 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.96\n",
            "Confusion Matrix:\n",
            " [[719  20]\n",
            " [ 18 278]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       739\n",
            "           1       0.93      0.94      0.94       296\n",
            "\n",
            "    accuracy                           0.96      1035\n",
            "   macro avg       0.95      0.96      0.96      1035\n",
            "weighted avg       0.96      0.96      0.96      1035\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load your cleaned dataset (replace 'cleaned_dataset.csv' with the actual file name)\n",
        "df_cleaned = pd.read_csv('cleaned_dataset.csv')\n",
        "\n",
        "# Assuming 'target' is the column you want to predict\n",
        "target_column = 'Prediction'\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df_cleaned.drop(columns=[target_column])\n",
        "y = df_cleaned[target_column]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer and first hidden layer\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = [1 if prob >= 0.5 else 0 for prob in y_pred_prob]\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ]
    }
  ]
}